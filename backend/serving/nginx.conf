# Nginx Load Balancer for TorchServe
# Arabic: موازن الحمل لخدمة النماذج

events {
    worker_connections 1024;
}

http {
    # Upstream configuration for TorchServe instances
    upstream torchserve_inference {
        least_conn;
        server torchserve:8080;
        # Add more servers for scaling:
        # server torchserve-2:8080;
        # server torchserve-3:8080;

        keepalive 32;
    }

    upstream torchserve_management {
        server torchserve:8081;
    }

    upstream torchserve_metrics {
        server torchserve:8082;
    }

    # Logging
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    'rt=$request_time uct="$upstream_connect_time" '
                    'uht="$upstream_header_time" urt="$upstream_response_time"';

    access_log /var/log/nginx/access.log main;
    error_log /var/log/nginx/error.log warn;

    # Gzip compression
    gzip on;
    gzip_types application/json;

    # Server configuration
    server {
        listen 80;
        server_name localhost;

        # Inference API
        location /predictions/ {
            proxy_pass http://torchserve_inference;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;

            # Timeouts
            proxy_connect_timeout 10s;
            proxy_send_timeout 120s;
            proxy_read_timeout 120s;

            # Buffer settings
            proxy_buffering on;
            proxy_buffer_size 16k;
            proxy_buffers 4 32k;
            proxy_busy_buffers_size 64k;
        }

        # Ping endpoint
        location /ping {
            proxy_pass http://torchserve_inference/ping;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
        }

        # Management API (restricted)
        location /models {
            # Restrict to internal network in production
            # allow 10.0.0.0/8;
            # allow 172.16.0.0/12;
            # allow 192.168.0.0/16;
            # deny all;

            proxy_pass http://torchserve_management;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
        }

        # Metrics endpoint
        location /metrics {
            proxy_pass http://torchserve_metrics;
            proxy_http_version 1.1;
            proxy_set_header Connection "";
        }

        # Health check
        location /health {
            access_log off;
            return 200 'OK';
            add_header Content-Type text/plain;
        }
    }
}
