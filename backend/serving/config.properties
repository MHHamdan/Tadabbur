# TorchServe Configuration for Tadabbur Cross-Encoder Model
# Arabic: إعدادات TorchServe لنموذج إعادة الترتيب

# Inference endpoint configuration
inference_address=http://0.0.0.0:8080
management_address=http://0.0.0.0:8081
metrics_address=http://0.0.0.0:8082

# Model settings
load_models=all
models={\
  "cross-encoder": {\
    "1.0": {\
        "defaultVersion": true,\
        "marName": "cross_encoder.mar",\
        "minWorkers": 1,\
        "maxWorkers": 4,\
        "batchSize": 32,\
        "maxBatchDelay": 100,\
        "responseTimeout": 120\
    }\
  }\
}

# Worker configuration
number_of_netty_threads=8
job_queue_size=100

# GPU configuration (set device_type to gpu if CUDA available)
device_type=cpu
number_of_gpu=0

# Batch inference settings
max_request_size=6553500
max_response_size=6553500

# Async logging for performance
async_logging=true

# Enable metrics
enable_metrics_api=true
metrics_format=prometheus

# Model store location
model_store=/models

# Snapshot configuration
snapshot_store=/snapshots

# Blacklist environment variables for security
blacklist_env_vars=AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY
